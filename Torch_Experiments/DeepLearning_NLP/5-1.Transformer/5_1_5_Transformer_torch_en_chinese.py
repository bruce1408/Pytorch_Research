import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import os
from collections import Counter
from torch.utils.data import Dataset, DataLoader
import re

# ==========================================
# 1. é…ç½®ä¸ç¯å¢ƒ
# ==========================================
SEED = 1234
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.backends.cudnn.deterministic = True

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ Using device: {device}")

# ================================ fake data for testing ==========================================
# # ä½ çš„æ ·æœ¬æ•°æ® (ç›´æ¥å†™å…¥æ–‡ä»¶æ¨¡æ‹ŸçœŸå®ç¯å¢ƒ)
# RAW_DATA = """I'll sautÃ© a few sweet potatoes and sprinkle them with sugar.\tæˆ‘å»ç‚¸ä¸€é»ç´…è–¯ï¼Œç„¶å¾Œåœ¨ä¸Šé¢æ’’ä¸Šç³–ã€‚\tCC-BY 2.0
# I've been a public school teacher for the past thirteen years.\téå» 13 å¹´ï¼Œæˆ‘éƒ½æ˜¯å…¬ç«‹å­¸æ ¡çš„è€å¸«ã€‚\tCC-BY 2.0
# If someone irritates you, it is best not to react immediately.\tå¦‚æœæœ‰äººæ¿€æ€’ä½ ï¼Œä½ æœ€å¥½ä¸è¦ç«‹åˆ»åšå‡ºååº”ã€‚\tCC-BY 2.0
# If they hadn't noticed, there wouldn't have been any problems.\tè¦æ˜¯ä»–ä»¬æ²¡æœ‰å‘ç°ï¼Œå°±æ²¡é—®é¢˜äº†ã€‚\tCC-BY 2.0
# Islam first reached China about the middle of the 7th century.\tä¼Šæ–¯è˜­æ•™å¤§ç´„åœ¨ä¸ƒä¸–çºªä¸­å‚³åˆ°ä¸­åœ‹ã€‚\tCC-BY 2.0
# It is becoming important for us to know how to use a computer.\tçŸ¥é“å¦‚ä½•ä½¿ç”¨ç”µè„‘å¯¹æˆ‘ä»¬æ¥è¯´å˜å¾—å¾ˆé‡è¦ã€‚\tCC-BY 2.0
# Japan is now very different from what it was twenty years ago.\tç›¸æ¯”äºŒåå¹´å‰çš„æ—¥æœ¬ï¼Œç°åœ¨çš„æ—¥æœ¬æœ‰äº†ç¿»å¤©è¦†åœ°çš„å˜åŒ–ã€‚\tCC-BY 2.0
# Japan is now very different from what it was twenty years ago.\tç°åœ¨çš„æ—¥æœ¬ä¸äºŒåå¹´å‰å¤§ä¸ç›¸åŒã€‚\tCC-BY 2.0
# Language is the means by which people communicate with others.\tè¯­è¨€æ˜¯äººä»¬ä¸ä»–äººäº¤æµçš„æ‰‹æ®µã€‚\tCC-BY 2.0
# Let me stop you right there. We don't want to hear about that.\tè®“æˆ‘åœ¨é€™æ‰“æ–·ä½ ã€‚æˆ‘å€‘ä¸æƒ³è½é‚£å€‹è©±é¡Œã€‚\tCC-BY 2.0
# London was very important for economical and cultural reasons.\tå€«æ•¦éå»å› ç‚ºç¶“æ¿Ÿå’Œæ–‡åŒ–çš„ç·£æ•…ï¼Œååˆ†é‡è¦ã€‚\tCC-BY 2.0"""

# # å†™å…¥æœ¬åœ°æ–‡ä»¶ cmn.txt
# with open("cmn.txt", "w", encoding="utf-8") as f:
#     f.write(RAW_DATA)
# ================================ fake data for testing ==========================================

    
# è¶…å‚æ•°
MAX_LEN = 128           # å¥å­æœ€å¤§é•¿åº¦
BATCH_SIZE = 64        # æ ·æœ¬å°‘ï¼ŒBatch size è®¾å°ç‚¹
# ä¿®æ”¹åçš„å»ºè®® (æ ‡å‡† Base æ¨¡å‹è§„æ¨¡)
D_MODEL = 128           # åµŒå…¥ç»´åº¦å˜å¤§ (æ˜¾å­˜å ç”¨ä¸»è¦æ¥æºä¹‹ä¸€) d_k * n_heads
D_FF = 512             # å‰é¦ˆç½‘ç»œç»´åº¦å˜å¤§ (é€šå¸¸æ˜¯ D_MODEL * 4)
N_LAYERS = 3            # å±‚æ•°åŠ æ·± (è®¡ç®—é‡å’Œæ˜¾å­˜éƒ½ä¼šå¢åŠ )
N_HEADS = 4
D_K = D_V = 32
LR = 0.001
EPOCHS = 100            # æ ·æœ¬æå°‘ï¼Œå¤šè·‘å‡ è½®è¿‡æ‹Ÿåˆå®ƒï¼Œçœ‹çœ‹æ•ˆæœ
USE_AMP = False
# ==========================================
# 2. æ•°æ®é›†å‡†å¤‡ (é€‚é…ä¸­æ–‡)
# ==========================================
class En2ZhDataset(Dataset):
    def __init__(self):
        self.file_path = "/home/bruce_ultra/data/datasets/cmn.txt"
        # self.file_path = "cmn.txt"
        self.raw_data = []
        
        # è¯»å–æ•°æ®
        with open(self.file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            for line in lines:
                parts = line.strip().split('\t')
                if len(parts) >= 2:
                    eng, zho = parts[0], parts[1]
                    # 1. è‹±æ–‡åˆ†è¯ (æŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹)
                    src_tokens = self.tokenize_en(eng)
                    # 2. ä¸­æ–‡åˆ†è¯ (æŒ‰å­—åˆ‡åˆ†ï¼ŒCharacter-level)
                    tgt_tokens = self.tokenize_cn(zho)
                    
                    self.raw_data.append((src_tokens, tgt_tokens))

        # æ„å»ºè¯è¡¨
        self.src_vocab, self.src_idx2word = self.build_vocab([x[0] for x in self.raw_data])
        self.tgt_vocab, self.tgt_idx2word = self.build_vocab([x[1] for x in self.raw_data], is_target=True)
        
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(self.raw_data)} æ¡")
        print(f"âœ… æºè¯­è¨€è¯è¡¨(è‹±æ–‡): {len(self.src_vocab)}")
        print(f"âœ… ç›®æ ‡è¯­è¨€è¯è¡¨(ä¸­æ–‡-å­—çº§): {len(self.tgt_vocab)}")

    
    def tokenize_en(self, text):
        text = text.lower()
        # æŠŠæ ‡ç‚¹ç¬¦å·ç”¨ç©ºæ ¼éš”å¼€ï¼Œè¿™æ · split å°±èƒ½æŠŠå®ƒä»¬ç‹¬ç«‹å‡ºæ¥
        text = re.sub(r"([?.!,])", r" \1 ", text)
        # å»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'[" "]+', " ", text)
        return text.strip().split()

    def tokenize_cn(self, text):
        # ä¸­æ–‡æŒ‰å­—åˆ‡åˆ†æ˜¯æ²¡é—®é¢˜çš„
        return [char for char in text.strip()]
    
    
    # def tokenize_en(self, text):
    #     # è‹±æ–‡ï¼šè½¬å°å†™ï¼ŒæŠŠæ ‡ç‚¹ç¬¦å·å•ç‹¬æ‹†å‡ºæ¥
    #     text = text.lower()
    #     text = re.sub(r"([?.!,])", r" \1 ", text) # åœ¨æ ‡ç‚¹å‰ååŠ ç©ºæ ¼
    #     text = re.sub(r'[" "]+', " ", text)       # åˆå¹¶å¤šä½™ç©ºæ ¼
    #     return text.strip().split()

    # def tokenize_cn(self, text):
    #     # ä¸­æ–‡ï¼šå­—çº§åˆ«åˆ†è¯ (æ¯ä¸ªæ±‰å­—ç®—ä¸€ä¸ªtoken)
    #     # è¿™ç§æ–¹æ³•æœ€ç®€å•ä¸”ä¸éœ€è¦å®‰è£… jieba
    #     return [char for char in text.strip()]

    def build_vocab(self, sentences, is_target=False):
        counter = Counter()
        for sent in sentences:
            counter.update(sent)
        
        # 0:Pad, 1:Unk
        vocab = {'<P>': 0, '<UNK>': 1}
        if is_target:
            vocab['<S>'] = 2
            vocab['<E>'] = 3
        
        # å°†æ‰€æœ‰è¯åŠ å…¥è¯å…¸
        for word, _ in counter.items():
            if word not in vocab:
                vocab[word] = len(vocab)
            
        idx2word = {v: k for k, v in vocab.items()}
        return vocab, idx2word

    def __len__(self):
        return len(self.raw_data)

    def __getitem__(self, idx):
        src_tokens, tgt_tokens = self.raw_data[idx]
        
        # è½¬ ID
        src_ids = [self.src_vocab.get(w, self.src_vocab['<UNK>']) for w in src_tokens]
        tgt_ids = [self.tgt_vocab.get(w, self.tgt_vocab['<UNK>']) for w in tgt_tokens]
        
        # æˆªæ–­
        src_ids = src_ids[:MAX_LEN]
        tgt_ids = tgt_ids[:MAX_LEN]
        
        # Decoder Input: <S> + å¥å­
        dec_input = [self.tgt_vocab['<S>']] + tgt_ids
        
        # Target Label: å¥å­ + <E>
        dec_label = tgt_ids + [self.tgt_vocab['<E>']]
        
        return torch.LongTensor(src_ids), torch.LongTensor(dec_input), torch.LongTensor(dec_label)

def collate_fn(batch):
    src_list, dec_input_list, dec_label_list = [], [], []
    for src, dec_in, dec_lbl in batch:
        src_list.append(src)
        dec_input_list.append(dec_in)
        dec_label_list.append(dec_lbl)
    
    src_pad = nn.utils.rnn.pad_sequence(src_list, batch_first=True, padding_value=0)
    dec_in_pad = nn.utils.rnn.pad_sequence(dec_input_list, batch_first=True, padding_value=0)
    dec_lbl_pad = nn.utils.rnn.pad_sequence(dec_label_list, batch_first=True, padding_value=0)
    
    return src_pad, dec_in_pad, dec_lbl_pad

# åˆå§‹åŒ–æ•°æ®
dataset = En2ZhDataset()
# dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)

# åœ¨ DataLoader ä¸­æ·»åŠ  num_workers
dataloader = DataLoader(
    dataset, 
    batch_size=BATCH_SIZE, 
    shuffle=True, 
    collate_fn=collate_fn,
    num_workers=8,        # è®¾ç½®ä¸º 4 æˆ– 8 (å–å†³äºä½  CPU çš„æ ¸å¿ƒæ•°)
    pin_memory=True       # å¼€å¯é”é¡µå†…å­˜ï¼ŒåŠ é€Ÿ CPU åˆ° GPU çš„ä¼ è¾“
)

# ==========================================
# 3. Transformer æ¨¡å‹ (ä¿æŒåŸæ ·ï¼Œæ— éœ€ä¿®æ”¹)
# ==========================================
def get_attn_pad_mask(seq_q, seq_k):
    batch_size, len_q = seq_q.size()
    batch_size, len_k = seq_k.size()
    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)
    return pad_attn_mask.expand(batch_size, len_q, len_k)

def get_attn_subsequent_mask(seq):
    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]
    subsequent_mask = np.triu(np.ones(attn_shape), k=1)
    return torch.from_numpy(subsequent_mask).byte().to(seq.device)

class ScaledDotProductAttention(nn.Module):
    def __init__(self):
        super().__init__()
    def forward(self, Q, K, V, attn_mask):
        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(D_K)
        scores.masked_fill_(attn_mask, -1e9)
        # scores.masked_fill_(attn_mask, -1e4) # Fills elements of self tensor with value where mask is True.

        attn = nn.Softmax(dim=-1)(scores)
        context = torch.matmul(attn, V)
        return context, attn

class MultiHeadAttention(nn.Module):
    def __init__(self):
        super().__init__()
        self.W_Q = nn.Linear(D_MODEL, D_K * N_HEADS)
        self.W_K = nn.Linear(D_MODEL, D_K * N_HEADS)
        self.W_V = nn.Linear(D_MODEL, D_V * N_HEADS)
        self.linear = nn.Linear(N_HEADS * D_V, D_MODEL)
        self.layer_norm = nn.LayerNorm(D_MODEL)
    def forward(self, Q, K, V, attn_mask):
        residual, batch_size = Q, Q.size(0)
        q_s = self.W_Q(Q).view(batch_size, -1, N_HEADS, D_K).transpose(1, 2)
        k_s = self.W_K(K).view(batch_size, -1, N_HEADS, D_K).transpose(1, 2)
        v_s = self.W_V(V).view(batch_size, -1, N_HEADS, D_V).transpose(1, 2)
        attn_mask = attn_mask.unsqueeze(1).repeat(1, N_HEADS, 1, 1)
        context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)
        context = context.transpose(1, 2).contiguous().view(batch_size, -1, N_HEADS * D_V)
        output = self.linear(context)
        return self.layer_norm(output + residual), attn

class PoswiseFeedForwardNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(D_MODEL, D_FF)
        self.fc2 = nn.Linear(D_FF, D_MODEL)
        self.relu = nn.ReLU()
        self.layer_norm = nn.LayerNorm(D_MODEL)
    def forward(self, inputs):
        residual = inputs
        output = self.fc2(self.relu(self.fc1(inputs)))
        return self.layer_norm(output + residual)

class EncoderLayer(nn.Module):
    def __init__(self):
        super().__init__()
        self.enc_self_attn = MultiHeadAttention()
        self.pos_ffn = PoswiseFeedForwardNet()
    def forward(self, enc_inputs, enc_self_attn_mask):
        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)
        enc_outputs = self.pos_ffn(enc_outputs)
        return enc_outputs, attn

class DecoderLayer(nn.Module):
    def __init__(self):
        super().__init__()
        self.dec_self_attn = MultiHeadAttention()
        self.dec_enc_attn = MultiHeadAttention()
        self.pos_ffn = PoswiseFeedForwardNet()
    def forward(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):
        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)
        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)
        dec_outputs = self.pos_ffn(dec_outputs)
        return dec_outputs, dec_self_attn, dec_enc_attn

class Encoder(nn.Module):
    def __init__(self):
        super(Encoder, self).__init__()
        self.src_emb = nn.Embedding(len(dataset.src_vocab), D_MODEL)
        self.pos_emb = nn.Embedding(MAX_LEN + 1, D_MODEL)
        self.layers = nn.ModuleList([EncoderLayer() for _ in range(N_LAYERS)])
    def forward(self, enc_inputs):
        seq_len = enc_inputs.size(1)
        pos = torch.arange(seq_len, dtype=torch.long, device=enc_inputs.device).unsqueeze(0).expand_as(enc_inputs)
        enc_outputs = self.src_emb(enc_inputs) + self.pos_emb(pos)
        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs)
        enc_self_attns = []
        for layer in self.layers:
            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)
            enc_self_attns.append(enc_self_attn)
        return enc_outputs, enc_self_attns

class Decoder(nn.Module):
    def __init__(self):
        super(Decoder, self).__init__()
        self.tgt_emb = nn.Embedding(len(dataset.tgt_vocab), D_MODEL)
        self.pos_emb = nn.Embedding(MAX_LEN + 1, D_MODEL)
        self.layers = nn.ModuleList([DecoderLayer() for _ in range(N_LAYERS)])
    def forward(self, enc_inputs, dec_inputs, enc_outputs):
        seq_len = dec_inputs.size(1)
        pos = torch.arange(seq_len, dtype=torch.long, device=dec_inputs.device).unsqueeze(0).expand_as(dec_inputs)
        dec_outputs = self.tgt_emb(dec_inputs) + self.pos_emb(pos)
        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs)
        dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_inputs)
        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)
        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs)
        dec_self_attns, dec_enc_attns = [], []
        for layer in self.layers:
            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)
            dec_self_attns.append(dec_self_attn)
            dec_enc_attns.append(dec_enc_attn)
        return dec_outputs, dec_self_attns, dec_enc_attns

class Transformer(nn.Module):
    def __init__(self):
        super(Transformer, self).__init__()
        self.encoder = Encoder()
        self.decoder = Decoder()
        self.projection = nn.Linear(D_MODEL, len(dataset.tgt_vocab), bias=False)
    def forward(self, enc_inputs, dec_inputs):
        enc_outputs, enc_self_attns = self.encoder(enc_inputs)
        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(enc_inputs, dec_inputs, enc_outputs)
        dec_logits = self.projection(dec_outputs)
        return dec_logits.view(-1, dec_logits.size(-1)), enc_self_attns, dec_self_attns, dec_enc_attns


def eval_model(model, dataset):
    # ==========================================
    # 5. æµ‹è¯• (è´ªå©ªè§£ç )
    # ==========================================
    print("\nğŸ§ª æµ‹è¯•æœ€åä¸€æ¡æ•°æ®:")
    # å–æœ€åä¸€æ¡é•¿ä¸€ç‚¹çš„å¥å­: "Let me stop you right there..."
    test_sample = dataset.raw_data[-1] 
    src_text = "Let me stop you right there." # æ‰‹åŠ¨æŒ‡å®šä¸€ä¸ªæµ‹è¯•å¥ï¼Œçœ‹æ•ˆæœ
    src_text = "If you had left home a little earlier you would have been in time."
    print(f"åŸæ–‡ (En): {src_text}")

    model.eval()
    # æ„é€ è¾“å…¥
    src_tokens = dataset.tokenize_en(src_text)
    src_idxs = [dataset.src_vocab.get(w, 1) for w in src_tokens][:MAX_LEN]
    src_tensor = torch.LongTensor([src_idxs]).to(device)

    # è§£ç 
    dec_input = torch.LongTensor([[dataset.tgt_vocab['<S>']]]).to(device)

    print("é¢„æµ‹ (Zh): ", end="")
    for i in range(MAX_LEN):
        with torch.no_grad():
            outputs, _, _, _ = model(src_tensor, dec_input)
            pred_token = outputs.argmax(dim=1)[-1].item()
            
            if pred_token == dataset.tgt_vocab['<E>']:
                break
                
            print(dataset.tgt_idx2word[pred_token], end="") # ä¸­æ–‡ä¸éœ€è¦ç©ºæ ¼æ‹¼æ¥
            
            dec_input = torch.cat([dec_input, torch.LongTensor([[pred_token]]).to(device)], dim=1)
    print("\n")
    
    
# ==========================================
# 4. è®­ç»ƒå¾ªç¯
# ==========================================
model = Transformer().to(device)
criterion = nn.CrossEntropyLoss(ignore_index=0)
# optimizer = optim.Adam(model.parameters(), lr=LR)
optimizer = optim.Adam(model.parameters(), lr=0.0005, betas=(0.9, 0.98), eps=1e-9)

# 3. æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨
scheduler = torch.optim.lr_scheduler.OneCycleLR(
        optimizer, max_lr=0.0005, steps_per_epoch=len(dataloader), epochs=EPOCHS, pct_start=0.15
)
    
print(f"ğŸ”¥ å¼€å§‹è®­ç»ƒ {EPOCHS} ä¸ª Epochs (æ•°æ®é‡: {len(dataset)} æ¡)...")
model.train()

for epoch in range(EPOCHS):
    total_loss = 0
    for i, (enc_inputs, dec_inputs, dec_targets) in enumerate(dataloader):
        enc_inputs, dec_inputs, dec_targets = enc_inputs.to(device), dec_inputs.to(device), dec_targets.to(device)
        optimizer.zero_grad()
        
        
        
        if USE_AMP:
            # å¼€å¯è‡ªåŠ¨æ··åˆç²¾åº¦ä¸Šä¸‹æ–‡
            with torch.cuda.amp.autocast():
                outputs, _, _, _ = model(enc_inputs, dec_inputs)
                loss = criterion(outputs, dec_targets.view(-1))
        else:
            outputs, _, _, _ = model(enc_inputs, dec_inputs)
            loss = criterion(outputs, dec_targets.view(-1))
            
        loss.backward()
        optimizer.step()
        scheduler.step() # æ›´æ–°å­¦ä¹ ç‡
        total_loss += loss.item()
    
    if (epoch + 1) % 2 == 0:
        print(f"Epoch [{epoch+1}/{EPOCHS}] Loss: {total_loss / len(dataloader):.4f}")

    if (epoch + 1) % 10 == 0:
        eval_model(model, dataset)

MODEL_SAVE_PATH = "transformer_en_zh.pth" 
torch.save(model.state_dict(), MODEL_SAVE_PATH)
print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {MODEL_SAVE_PATH}")

eval_model(model, dataset)